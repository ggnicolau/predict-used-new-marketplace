mean_squared_error_test = 0.3640702047156597
Roc_auc = 0.8888785004424654
Brier_error = 0.13254711396170238
Logloss_test = 0.4085390232688165


mean_squared_error_test = 0.3556699052275815
Roc_auc = 0.901380382369481
Brier_error = 0.12650108148459682
Logloss_test = 0.3976958266550089


mean_squared_error_test = 0.3235110842811327
Roc_auc = 0.9313436124842018
Brier_error = 0.10465942165275412
Logloss_test = 0.34088933199467136




0.099
0.12928
0.13254


Logistic loss (or log loss) is a performance metric for evaluating the predictions of probabilities of membership to a given class.

The scalar probability between 0 and 1 can be seen as a measure of confidence for a prediction by an algorithm. Predictions that are correct or incorrect are rewarded or punished proportionally to the confidence of the prediction.



Area Under ROC Curve (or ROC AUC for short) is a performance metric for binary classification problems.

The AUC represents a modelâ€™s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random.

A ROC Curve is a plot of the true positive rate and the false positive rate for a given set of probability predictions at different thresholds used to map the probabilities to class labels. The area under the curve is then the approximate integral under the ROC Curve.



The Mean Squared Error (or MSE) is much like the mean absolute error in that it provides a gross idea of the magnitude of error.

Taking the square root of the mean squared error converts the units back to the original units of the output variable and can be meaningful for description and presentation. This is called the Root Mean Squared Error (or RMSE).

You can learn more about Mean Squared Error on Wikipedia.

The example below provides a demonstration of calculating mean squared error.
